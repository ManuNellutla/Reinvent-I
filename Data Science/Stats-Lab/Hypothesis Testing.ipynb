{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Hypothesis via hypothesis testing \n",
    "\n",
    "__$$ if p < 0.05 : H_0 should go$$__\n",
    "\n",
    "- __p <= alpha: reject H0, different distribution.__\n",
    "- __p > alpha: fail to reject H0, same distribution.__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1: mean=50.303 stdv=4.426\n",
      "data2: mean=51.764 stdv=4.660\n",
      "data3: mean=52.049 stdv=5.025\n"
     ]
    }
   ],
   "source": [
    "# generate gaussian data samples\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two sets of univariate observations\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "data3 = 5 * randn(100) + 52\n",
    "# summarize\n",
    "print('data1: mean=%.3f stdv=%.3f' % (mean(data1), std(data1)))\n",
    "print('data2: mean=%.3f stdv=%.3f' % (mean(data2), std(data2)))\n",
    "print('data3: mean=%.3f stdv=%.3f' % (mean(data3), std(data3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mann- whitney U test\n",
    "\n",
    "The Mann-Whitney U test is a nonparametric statistical significance test for determining whether two independent samples were drawn from a population with the same distribution.\n",
    "\n",
    ">The two samples are combined and rank ordered together. The strategy is to determine if the values from the two samples are randomly mixed in the rank ordering or if they are clustered at opposite ends when combined. A random rank order would mean that the two samples are not different, while a cluster of one sample values would indicate a difference between them.\n",
    "\n",
    "- __Fail to Reject H0:__ Sample distributions are equal.\n",
    "- __Reject H0:__ Sample distributions are not equal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=4025.000, p=0.009\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Mann-Whitney U test\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# compare samples\n",
    "stat, p = mannwhitneyu(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wilcoxon signed-rank test\n",
    "\n",
    ">The Wilcoxon signed ranks test is a nonparametric statistical procedure for comparing two samples that are paired, or related. The parametric equivalent to the Wilcoxon signed ranks test goes by names such as the Studentâ€™s t-test, t-test for matched pairs, t-test for paired samples, or t-test for dependent samples.\n",
    "\n",
    "- __Fail to Reject H0:__ Sample distributions are equal.\n",
    "- __Reject H0:__ Sample distributions are not equal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=1886.000, p=0.028\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Wilcoxon signed-rank test\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# compare samples\n",
    "stat, p = wilcoxon(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kruskal-Wallis H-test\n",
    "\n",
    ">When the Kruskal-Wallis H-test leads to significant results, then at least one of the samples is different from the other samples. However, the test does not identify where the difference(s) occur. Moreover, it does not identify how many differences occur. To identify the particular differences between sample pairs, a researcher might use sample contrasts, or post hoc tests, to analyze the specific sample pairs for significant difference(s). The Mann-Whitney U-test is a useful method for performing sample contrasts between individual sample sets.\n",
    "\n",
    "- __Fail to Reject H0:__ All sample distributions are equal.\n",
    "- __Reject H0:__ One or more sample distributions are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=7.576, p=0.023\n",
      "Different distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Kruskal-Wallis H-test\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# compare samples\n",
    "stat, p = kruskal(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friedman test\n",
    "\n",
    ">The Friedman test is a nonparametric statistical procedure for comparing more than two samples that are related. The parametric equivalent to this test is the repeated measures analysis of variance (ANOVA). When the Friedman test leads to significant results, at least one of the samples is different from the other samples.\n",
    "\n",
    "- __Fail to Reject H0:__ Paired sample distributions are equal.\n",
    "- __Reject H0:__ Paired sample distributions are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=9.780, p=0.008\n",
      "Different distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Friedman test\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "stat, p = friedmanchisquare(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
